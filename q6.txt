
#w3q6
from collections import defaultdict
import numpy as np
class NgramModel:
    def __init__(self,n,k=1):
        self.n=n
        self.k=k
        self.ngram_counts=defaultdict(int)
        self.context_counts=defaultdict(int)
    def train(self,corpus):
        for sentence in corpus:
            words = sentence.split()
            for i in range(len(words)-self.n+1):
                ngram = tuple(words[i:i+self.n-1])
                next_word = words[i+self.n-1]
                self.ngram_counts[(ngram,next_word)] += 1
                self.context_counts[ngram] += 1
    def probability(self,ngram,next_word):
        context = ngram[:-1]
        context_count = self.context_counts[context]
        ngram_count = self.ngram_counts[(ngram,next_word)]
        unique_words = len(self.ngram_counts)
        return (ngram_count+self.k)/(context_count+self.k*unique_words)
    def generate_next_word(self,ngram):
        possible_next_words = [word for ngram_, word in self.ngram_counts.keys() if ngram_ == ngram]
        probabilities = [self.probability(ngram,word) for word in possible_next_words]
        return np.random.choice(possible_next_words, p=probabilities)
corpus = ["this is a cat","this is a dog","this is a cat"]
ngram_model = NgramModel(n=2,k=1)
ngram_model.train(corpus)
ngram=("is",)
next_word=ngram_model.generate_next_word(ngram)
print(next_word)